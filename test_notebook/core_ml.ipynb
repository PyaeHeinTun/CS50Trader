{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 Import\n",
    "import ccxt as ccxt\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from typing import TypeVar,Type,Callable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Fetch Data\n",
    "def fetch_ohlcv_info(exchange: ccxt.binance, symbol, timeframe, limit) -> pd.DataFrame:\n",
    "    # Fetch 10,000 candles in chunks of 1500 candles\n",
    "    num_candles_to_fetch = limit\n",
    "    candles_per_request = 1000\n",
    "    start_index = 0\n",
    "    dataframe = pd.DataFrame()\n",
    "\n",
    "    while start_index < num_candles_to_fetch:\n",
    "        # Determine the end index for this request\n",
    "        end_index = min(start_index + candles_per_request,\n",
    "                        num_candles_to_fetch)\n",
    "\n",
    "        # Fetch candles for this chunk\n",
    "        candles = exchange.fetch_ohlcv(\n",
    "            symbol, timeframe, limit=candles_per_request, since=None)\n",
    "\n",
    "        # Convert candles to DataFrame\n",
    "        df = pd.DataFrame(candles, columns=[\n",
    "                          'date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        df['date'] = pd.to_datetime(df['date'], unit='ms')\n",
    "        # Append the candles to the DataFrame\n",
    "        dataframe = pd.concat([dataframe, df], ignore_index=True)\n",
    "\n",
    "        # Update start index for the next request\n",
    "        start_index += candles_per_request\n",
    "    return dataframe\n",
    "\n",
    "exchange = ccxt.binance()\n",
    "symbol = \"BTC/USDT:USDT\"\n",
    "df = fetch_ohlcv_info(exchange,symbol,\"1m\",4000)\n",
    "\n",
    "markets = exchange.load_markets()\n",
    "tick_size = float(markets[symbol]['info']['filters'][0]['tickSize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"timeframe\": \"1m\",\n",
    "    \"trade_params\": {\n",
    "        \"leverage\": 20,\n",
    "        \"stake_ammount\": 2\n",
    "    },\n",
    "    \"max_open_trade\": 1,\n",
    "    \"dry_run\": True,\n",
    "    \"dry_run_wallet\": 100,\n",
    "    \"exchange\": {\n",
    "        \"test_key\": \"52a65ac457d28e61c7f76a769754b3bdfe413d7c62e09a8605b55aaa140e9284\",\n",
    "        \"test_secret\": \"c86f35f7b8e4f75154ef39c650ff1513657a67799a51ee7429dd4d64939ba386\",\n",
    "        \"real_key\": \"D2Ww9DeCDd6UNP9eMUND2Qv9vwJmK8CGeB8GjN0R2ZaCA4G1koUEYE5min5z07OX\",\n",
    "        \"real_secret\": \"uIZRZqxgkPUclI2hpRXXyvGFtqbxTv7fGflMSDfmPnGhBuNsCXwu2M6ysAok5Kv9\",\n",
    "        \"pair_whitelist\": [\n",
    "            \"1000BONK/USDT:USDT\",\n",
    "            \"BTC/USDT:USDT\",\n",
    "            \"SOL/USDT:USDT\"\n",
    "        ],\n",
    "        \"type\": \"future\",\n",
    "        \"ohlcv_candle_limit\": 2000\n",
    "    },\n",
    "    \"telegram\": {\n",
    "        \"token\": \"7026320361:AAEkPW07NV9ki5D9dC10-l4oN8O4piDmC2M\",\n",
    "        \"user_id\": \"2146800175\",\n",
    "        \"chat_id\": \"2146800175\"\n",
    "    },\n",
    "    \"process_throttle_secs\": 0.1,\n",
    "    \"training_params\": {\n",
    "        \"filter_method\": [],\n",
    "        \"filter_params\": {\n",
    "            \"regime\": {\n",
    "                \"threshold\": -0.1\n",
    "            },\n",
    "            \"trend\": {\n",
    "                \"periods\": [\n",
    "                    0,\n",
    "                    5,\n",
    "                    10\n",
    "                ]\n",
    "            },\n",
    "            \"stc\": {\n",
    "                \"length\": 12,\n",
    "                \"fast\": 26,\n",
    "                \"slow\": 50\n",
    "            },\n",
    "            \"ut\": {\n",
    "                \"sensitivity\": 1,\n",
    "                \"atr_period\": 10\n",
    "            }\n",
    "        },\n",
    "        \"neighbor_count\": 8,\n",
    "        \"feature_count\": 5,\n",
    "        \"future_count\": 5,\n",
    "        \"f1\": {\n",
    "            \"name\": \"rsi\",\n",
    "            \"paramsA\": 3,\n",
    "            \"paramsB\": 2\n",
    "        },\n",
    "        \"f2\": {\n",
    "            \"name\": \"wt\",\n",
    "            \"paramsA\": 3,\n",
    "            \"paramsB\": 2\n",
    "        },\n",
    "        \"f3\": {\n",
    "            \"name\": \"cci\",\n",
    "            \"paramsA\": 3,\n",
    "            \"paramsB\": 2\n",
    "        },\n",
    "        \"f4\": {\n",
    "            \"name\": \"adx\",\n",
    "            \"paramsA\": 3,\n",
    "            \"paramsB\": 2\n",
    "        },\n",
    "        \"f5\": {\n",
    "            \"name\": \"rsi\",\n",
    "            \"paramsA\": 2,\n",
    "            \"paramsB\": 2\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class FeatureName(Enum):\n",
    "    rsi = \"RSI\"\n",
    "    wt = \"WT\"\n",
    "    cci = \"CCI\"\n",
    "    adx = \"ADX\"\n",
    "\n",
    "def rescale(src, old_min, old_max, new_min, new_max) -> np.ndarray:\n",
    "    return new_min + (new_max - new_min) * (src - old_min) / np.maximum((old_max - old_min), 10e-10)\n",
    "\n",
    "def n_rsi(src, n1, n2) -> pd.Series:\n",
    "    rsi = ta.rsi(src, n1)\n",
    "    ema_rsi = ta.ema(rsi, n2)\n",
    "    return rescale(ema_rsi, 0, 100, 0, 1)\n",
    "\n",
    "def calculate_cci_improved(source1: pd.Series, source2: pd.Series, source3: pd.Series, length) -> np.ndarray:\n",
    "    source1: np.ndarray = source1.to_numpy()\n",
    "    source2: np.ndarray = source2.to_numpy()\n",
    "    source3: np.ndarray = source3.to_numpy()\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(\n",
    "        source1, window_shape=(length,))\n",
    "    source3_modify = source3[:, np.newaxis][length-1:]\n",
    "    sums = np.sum(np.abs(windows - source3_modify), axis=1)\n",
    "\n",
    "    mad = sums / length\n",
    "\n",
    "    mad_series = pd.Series(index=range(len(source1)), dtype=float)\n",
    "    mad_series[-len(mad):] = mad\n",
    "    mad_series = mad_series.to_numpy()\n",
    "    source2_clean = np.nan_to_num(source2, nan=0.0)\n",
    "    mad_series_clean = np.nan_to_num(mad_series, nan=0.0)\n",
    "    mcci = np.divide(source2_clean, mad_series_clean, out=np.zeros_like(source2_clean), where=(mad_series_clean != 0))\n",
    "    # mcci = source2/mad_series/0.015\n",
    "    return mcci\n",
    "\n",
    "def n_cci(dataframe, n1, n2) -> pd.Series:\n",
    "    df = dataframe.copy()\n",
    "    source = df['close']\n",
    "\n",
    "    df['mas'] = ta.sma(source, n1)\n",
    "    df['diffs'] = source - df['mas']\n",
    "    df['cci'] = pd.Series(calculate_cci_improved(\n",
    "        dataframe['open'], df['diffs'], df['mas'], n1))\n",
    "\n",
    "    df['ema_cci'] = ta.ema(df['cci'], n2)\n",
    "\n",
    "    normalized_wt_diff = pd.Series(normalize_optimized(0, 1, df['ema_cci']))\n",
    "    return normalized_wt_diff\n",
    "\n",
    "def normalize_optimized(min_val, max_val, source: pd.Series):\n",
    "    source = source.to_numpy()\n",
    "    historic_min = 10e10\n",
    "    historic_max = -10e10\n",
    "    # source.fillna(historic_min)\n",
    "    src_filled_min = np.nan_to_num(source, historic_min)\n",
    "    # source.fillna(historic_max)\n",
    "    src_filled_max = np.nan_to_num(source, historic_max)\n",
    "    historic_min = np.minimum.accumulate(src_filled_min)\n",
    "    historic_max = np.maximum.accumulate(src_filled_max)\n",
    "    division_value = np.maximum((historic_max - historic_min), 10e-10)\n",
    "    normalized_src = (min_val + (max_val - min_val) *\n",
    "                      (source - historic_min)) / division_value\n",
    "    return normalized_src\n",
    "\n",
    "def n_wt(src, n1, n2) -> np.ndarray:\n",
    "    ema1 = ta.ema(src, n1)\n",
    "    ema2 = ta.ema(np.abs(src - ema1), n1)\n",
    "    ci = (src - ema1) / (0.015 * ema2)\n",
    "    wt1 = ta.ema(ci, n2)\n",
    "    wt2 = ta.sma(wt1, 4)\n",
    "    diff = wt1 - wt2\n",
    "    normalized_wt_diff = pd.Series(normalize_optimized(0, 1, pd.Series(diff)))\n",
    "    return normalized_wt_diff\n",
    "\n",
    "def calculate_tr_optimized(high, low, close) -> np.ndarray:\n",
    "    previos_close = np.roll(close, 1)\n",
    "\n",
    "    diff_h_n_l = high - low\n",
    "    abs_value_h_n_c = np.abs(high - previos_close)\n",
    "    abs_value_h_n_c[0] = abs(high[0] - 0)\n",
    "    abs_value_l_n_c = np.abs(low - previos_close)\n",
    "    abs_value_l_n_c[0] = abs(low[0] - 0)\n",
    "    tr = np.maximum(np.maximum(diff_h_n_l, abs_value_h_n_c), abs_value_l_n_c)\n",
    "    return tr\n",
    "\n",
    "def calculate_directionalMovementPlus_optimized(high, low) -> np.ndarray:\n",
    "    prev_high = np.roll(high, 1)\n",
    "    prev_low = np.roll(low, 1)\n",
    "\n",
    "    diff_h_n_ph = high - prev_high\n",
    "    diff_h_n_ph[0] = high[0] - 0\n",
    "    diff_pl_n_l = prev_low - low\n",
    "    diff_pl_n_l[0] = 0 - low[0]\n",
    "    dmp_value = np.maximum(diff_h_n_ph, 0) * (diff_h_n_ph > diff_pl_n_l)\n",
    "    return dmp_value\n",
    "\n",
    "def calculate_negMovement_optimized(high, low) -> np.ndarray:\n",
    "    prev_high = np.roll(high, 1)\n",
    "    prev_low = np.roll(low, 1)\n",
    "\n",
    "    diff_h_n_ph = high - prev_high\n",
    "    diff_h_n_ph[0] = high[0] - 0\n",
    "    diff_pl_n_l = prev_low - low\n",
    "    diff_pl_n_l[0] = 0 - low[0]\n",
    "    negMovement = np.maximum(diff_pl_n_l, 0) * (diff_pl_n_l > diff_h_n_ph)\n",
    "    return negMovement\n",
    "\n",
    "def n_adx_optimized(highSrc: pd.Series, lowSrc: pd.Series, closeSrc: pd.Series, n1: int):\n",
    "    length = n1\n",
    "    highSrc_numpy = highSrc.to_numpy()\n",
    "    lowSrc_numpy = lowSrc.to_numpy()\n",
    "    closeSrc_numpy = closeSrc.to_numpy()\n",
    "\n",
    "    tr = calculate_tr_optimized(highSrc_numpy, lowSrc_numpy, closeSrc_numpy)\n",
    "    directionalMovementPlus = calculate_directionalMovementPlus_optimized(\n",
    "        highSrc_numpy, lowSrc_numpy)\n",
    "    negMovement = calculate_negMovement_optimized(highSrc_numpy, lowSrc_numpy)\n",
    "\n",
    "    trSmooth = np.zeros_like(closeSrc_numpy)\n",
    "    trSmooth[0] = np.nan\n",
    "    for i in range(0, len(tr)):\n",
    "        trSmooth[i] = trSmooth[i-1] - trSmooth[i-1] / length + tr[i]\n",
    "\n",
    "    smoothDirectionalMovementPlus = np.zeros_like(closeSrc)\n",
    "    smoothDirectionalMovementPlus[0] = np.nan\n",
    "    for i in range(0, len(directionalMovementPlus)):\n",
    "        smoothDirectionalMovementPlus[i] = smoothDirectionalMovementPlus[i-1] - \\\n",
    "            smoothDirectionalMovementPlus[i-1] / \\\n",
    "            length + directionalMovementPlus[i]\n",
    "\n",
    "    smoothnegMovement = np.zeros_like(closeSrc)\n",
    "    smoothnegMovement[0] = np.nan\n",
    "    for i in range(0, len(negMovement)):\n",
    "        smoothnegMovement[i] = smoothnegMovement[i-1] - \\\n",
    "            smoothnegMovement[i-1] / length + negMovement[i]\n",
    "\n",
    "    diPositive = smoothDirectionalMovementPlus / trSmooth * 100\n",
    "    diNegative = smoothnegMovement / trSmooth * 100\n",
    "    dx = np.abs(diPositive - diNegative) / (diPositive + diNegative) * 100\n",
    "    dx_series = pd.Series(dx)\n",
    "\n",
    "    adx = dx_series.copy()\n",
    "    adx.iloc[:length] = adx.rolling(length).mean().iloc[:length]\n",
    "    adx = adx.ewm(alpha=(1.0/length), adjust=False).mean()\n",
    "    return rescale(adx, 0, 100, 0, 1)\n",
    "\n",
    "def chooseFeatureName(name: FeatureName, dataframe, paramsA, paramsB):\n",
    "    df = dataframe.copy()\n",
    "    source = df['open']\n",
    "    hlc3 = (df['high'] + df['low'] + df['open']) / 3\n",
    "    if (name == FeatureName.rsi.name):\n",
    "        return n_rsi(source, paramsA, paramsB)\n",
    "    if (name == FeatureName.wt.name):\n",
    "        return n_wt(hlc3, paramsA, paramsB)\n",
    "    if (name == FeatureName.cci.name):\n",
    "        return n_cci(df, paramsA, paramsB)\n",
    "    if (name == FeatureName.adx.name):\n",
    "        return n_adx_optimized(df['high'], df['low'], df['open'], paramsA)\n",
    "\n",
    "def highestvalue(_src,_len) -> np.ndarray:\n",
    "    rolling_windows = np.lib.stride_tricks.sliding_window_view(_src, window_shape=(_len,))\n",
    "    max_previous_value = np.max(rolling_windows, axis=1)\n",
    "    max_previous_value = np.concatenate([np.full(_len-1, np.nan), max_previous_value])\n",
    "    return max_previous_value\n",
    "\n",
    "def lowestvalue(_src,_len) -> np.ndarray:\n",
    "    rolling_windows = np.lib.stride_tricks.sliding_window_view(_src, window_shape=(_len,))\n",
    "    max_previous_value = np.min(rolling_windows, axis=1)\n",
    "    max_previous_value = np.concatenate([np.full(_len-1, np.nan), max_previous_value])\n",
    "    return max_previous_value\n",
    "\n",
    "def change_occurred(arr) -> np.ndarray:\n",
    "    differences = np.diff(arr)\n",
    "    differences = np.concatenate([np.full(1, 0), differences])\n",
    "    return differences != 0\n",
    "\n",
    "def set_h_l_value(high:np.ndarray,low:np.ndarray,direction:np.ndarray):\n",
    "    price_now_1 = low[0]\n",
    "    price_now_2 = high[0]\n",
    "    price_now = low[0]\n",
    "\n",
    "    price_index = 0\n",
    "    price_index_1 = 0\n",
    "    price_index_2 = 0\n",
    "\n",
    "    price_index_array_1 = np.zeros_like(high)\n",
    "    price_index_array_2 = np.zeros_like(high)\n",
    "    price_index_array = np.zeros_like(high)\n",
    "\n",
    "    for i in range(len(high)):\n",
    "        if direction[i] != direction[i-1]:\n",
    "            price_now_1 = price_now_2\n",
    "            price_index_1 = price_index_2\n",
    "            price_index_array_1[i] = price_index_1\n",
    "            price_now_2 = price_now\n",
    "            price_index_2 = price_index\n",
    "            price_index_array_2[i] = price_index_2\n",
    "\n",
    "        if direction[i] > 0:\n",
    "            if (high[i] > price_now_2):\n",
    "                price_now_2 = high[i]\n",
    "                price_index_2 = i\n",
    "                price_index_array_2[i] = price_index_2\n",
    "                price_now = low[i]\n",
    "                price_index = i\n",
    "                price_index_array[i] = price_index\n",
    "\n",
    "            if (low[i] < price_now):\n",
    "                price_now = low[i]\n",
    "                price_index = i\n",
    "                price_index_array[i] = price_index\n",
    "\n",
    "        if direction[i] < 0:\n",
    "            if (low[i] < price_now_2):\n",
    "                price_now_2 = low[i]\n",
    "                price_index_2 = i\n",
    "                price_index_array_2[i] = price_index_2\n",
    "                price_now = high[i]\n",
    "                price_index = i\n",
    "                price_index_array[i] = price_index\n",
    "\n",
    "            if (high[i] > price_now):\n",
    "                price_now = high[i]\n",
    "                price_index = i\n",
    "                price_index_array[i] = price_index\n",
    "    \n",
    "    return price_index_array_1,price_index_array_2\n",
    "\n",
    "def findBarSince(src: np.ndarray) -> np.ndarray:\n",
    "    true_indices = np.where(src)[0]\n",
    "    if len(true_indices) == 0:\n",
    "        return np.zeros_like(src, dtype=np.int64)\n",
    "    index_distance_array = np.full_like(src, fill_value=-1, dtype=np.int64)\n",
    "    for i in range(len(true_indices)):\n",
    "        if i == len(true_indices) - 1:\n",
    "            index_distance_array[true_indices[i]:] = np.arange(len(src) - true_indices[i])\n",
    "        else:\n",
    "            index_distance_array[true_indices[i]:true_indices[i + 1]] = np.arange(true_indices[i + 1] - true_indices[i])\n",
    "    index_distance_array[index_distance_array == -1] = 0\n",
    "    return index_distance_array\n",
    "\n",
    "def find_ytrain(z1:np.ndarray,z2:np.ndarray,direction:np.ndarray,high:np.ndarray,low:np.ndarray):\n",
    "    cutted_z1 = z1[direction != np.roll(direction,1)]\n",
    "    cutted_z2 = z2[direction != np.roll(direction,1)]\n",
    "    cutted_direction = direction[direction != np.roll(direction,1)]\n",
    "\n",
    "    iterator = zip(cutted_z1,cutted_direction)\n",
    "    result = np.zeros_like(direction)\n",
    "    previous_index = 0\n",
    "    for i,value in enumerate(iterator):\n",
    "        result[previous_index:int(value[0])+1] = value[1]\n",
    "        \n",
    "        previous_index = int(value[0])+1\n",
    "\n",
    "    while previous_index < len(z1)-1:\n",
    "        data_index_remainder = previous_index\n",
    "        result_remainder = result[data_index_remainder:] \n",
    "        direction_remainder = direction[data_index_remainder:]\n",
    "        high_remainder = high[data_index_remainder:]\n",
    "        low_remainder = low[data_index_remainder:]\n",
    "\n",
    "        max_index = np.argmax(high_remainder)+1\n",
    "        min_index = np.argmin(low_remainder)+1\n",
    "\n",
    "        if(result[data_index_remainder-1] == 1):\n",
    "            result_remainder[:max_index] = -1\n",
    "            result_remainder[max_index:] = 0\n",
    "            result_remainder = np.roll(result_remainder,1)\n",
    "            result_remainder[0] = -1\n",
    "            result[data_index_remainder:]  = result_remainder\n",
    "            previous_index = data_index_remainder + max_index\n",
    "        if(result[data_index_remainder-1] == -1):\n",
    "            result_remainder[:min_index] = 1   \n",
    "            result_remainder[min_index:] = 0\n",
    "            result_remainder = np.roll(result_remainder,1)\n",
    "            result_remainder[0] = 1\n",
    "            result[data_index_remainder:]  = result_remainder\n",
    "            previous_index = data_index_remainder + min_index\n",
    "        \n",
    "\n",
    "    # 1 into -1 and -1 into 1 Conversion\n",
    "    mask_1 = result == 1\n",
    "    mask_minus1 = result == -1\n",
    "    result[mask_1] = -1\n",
    "    result[mask_minus1] = 1\n",
    "    return result\n",
    "\n",
    "def zigzagpp(_high,_low,depth,deviation,backstep) -> tuple:\n",
    "    df = pd.DataFrame()\n",
    "    df['high'] = pd.Series(_high)\n",
    "    df['low'] = pd.Series(_low)\n",
    "\n",
    "    df['highest'] = highestvalue(df['high'],depth)\n",
    "    hr_condition = np.logical_not(((df['highest'] - df['high']) > (deviation * tick_size)).shift(1))\n",
    "    hr_condition = np.array(hr_condition, dtype=np.float64)\n",
    "    df['hr'] = findBarSince(hr_condition)\n",
    "\n",
    "    df['lowest'] = lowestvalue(df['low'],depth)\n",
    "    lr_condition = np.logical_not(((df['low'] - df['lowest']) > (deviation * tick_size)).shift(1))\n",
    "    lr_condition = np.array(lr_condition, dtype=np.float64)\n",
    "    df['lr'] = findBarSince(lr_condition)\n",
    "\n",
    "    difference_of_hr_lr_condition = np.logical_not(df['hr'] > df['lr'])\n",
    "    difference_of_hr_lr_condition = np.array(difference_of_hr_lr_condition,dtype=np.bool_)\n",
    "    difference_of_hr_lr = findBarSince(difference_of_hr_lr_condition) >= backstep\n",
    "    df['direction'] = np.where(difference_of_hr_lr,-1,1)\n",
    "\n",
    "    price_index_1 , price_index_2 = set_h_l_value(df['high'].values,df['low'].values,df['direction'].values)\n",
    "\n",
    "    price_index_1 = pd.Series(price_index_1)\n",
    "    price_index_2 = pd.Series(price_index_2)\n",
    "\n",
    "    return price_index_1,price_index_2,df['direction']\n",
    "\n",
    "def label_market_trend(df: pd.DataFrame, future_count: int = 2) -> pd.DataFrame:\n",
    "    z1,z2,direction = zigzagpp(df['high'],df['low'],5,2,2)\n",
    "    df['y_train'] = pd.Series(find_ytrain(z1.values,z2.values,direction.values,df['high'].values,df['low'].values)).shift(-1)\n",
    "    df.loc[df['y_train'] == 0,['y_train']] = np.nan\n",
    "    return df['y_train']\n",
    "\n",
    "def extract_features(dataframe: pd.DataFrame, training_params):\n",
    "    df = dataframe.copy()\n",
    "    future_count = training_params['future_count']\n",
    "    feature_count = training_params['feature_count']\n",
    "\n",
    "    for i in range(1, feature_count+1):\n",
    "        df[f'f{i}'] = chooseFeatureName(training_params[f'f{i}']['name'], df,\n",
    "                                        training_params[f'f{i}']['paramsA'], training_params[f'f{i}']['paramsB'])\n",
    "    df['y_train'] = label_market_trend(df,future_count)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df,training_params) -> VotingClassifier:\n",
    "    test_number = 0\n",
    "\n",
    "    dataframe = df.copy()\n",
    "    dataframe = dataframe\n",
    "    dataframe.dropna(inplace=True)\n",
    "    feature_count = training_params[\"feature_count\"]+1\n",
    "    feature_columns = [f'f{i}' for i in range(1, feature_count)]\n",
    "    df_features = dataframe[feature_columns]\n",
    "    df_y = dataframe['y_train']\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(df_features, df_y, test_size=0.1, random_state=42)\n",
    "    X_train = df_features[:len(df_features)-test_number]\n",
    "    X_test = df_features[len(df_features)-test_number:]\n",
    "    y_train = df_y[:len(df_y)-test_number]\n",
    "    y_test = df_y[len(df_y)-test_number:]\n",
    "    # Build Model\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    cat_model = CatBoostClassifier(\n",
    "        iterations=50,\n",
    "        verbose=False,\n",
    "        depth=2,\n",
    "        learning_rate=0.01,\n",
    "        loss_function='Logloss',\n",
    "        rsm=0.95,\n",
    "        border_count=64,\n",
    "        eval_metric='AUC',\n",
    "    )\n",
    "\n",
    "    model = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('knn', knn),\n",
    "            ('cat', cat_model),\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict Model\n",
    "    if test_number > 0:\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"Accuracy Test : {accuracy_score(y_test,y_pred)}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "def fractalFilters(predict_value: pd.Series):\n",
    "    isDifferentSignalType = predict_value.ne(predict_value.shift())\n",
    "    return isDifferentSignalType\n",
    " \n",
    "def predict_future(dataframe: pd.DataFrame, training_params) -> pd.DataFrame:\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    df['predicted_value'], df['predicted_proba'] = train_model(\n",
    "        df, training_params)\n",
    "    df['isDifferentSignalType'] = fractalFilters(df['predicted_value'])\n",
    "\n",
    "    dataframe['predicted_value'] = df['predicted_value']\n",
    "    dataframe['predicted_proba'] = df['predicted_proba']\n",
    "    dataframe['buy_signal'] = (df['predicted_value'] > 0) & (\n",
    "        df['isDifferentSignalType'])\n",
    "    dataframe['sell_signal'] = (df['predicted_value'] < 0) & (\n",
    "        df['isDifferentSignalType'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "class Singleton(type):\n",
    "    _instances = {}\n",
    "    def __call__(cls, *args, **kwargs) -> None:\n",
    "        if cls not in cls._instances:\n",
    "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "\n",
    "class CoreML(metaclass=Singleton):\n",
    "    \"\"\"Core Machine Learning class implementing a singleton pattern.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.model = None\n",
    "        self.extracted_data = None\n",
    "\n",
    "    def extract_features(self,df:pd.DataFrame,training_params: dict) -> pd.DataFrame:\n",
    "        self.extracted_data = extract_features(dataframe=df, training_params=training_params)\n",
    "        return self.extracted_data\n",
    "    \n",
    "\n",
    "    def train(self,df: pd.DataFrame, training_params: dict) -> None:\n",
    "        \"\"\"Train the model using the provided data and parameters.\"\"\"\n",
    "        self.extract_features(df,training_params)\n",
    "        self.model = train_model(self.extracted_data, training_params)\n",
    "\n",
    "        feature_count = training_params[\"feature_count\"]+1\n",
    "        feature_columns = [f'f{i}' for i in range(1, feature_count)]\n",
    "        data_for_predict = self.extracted_data[feature_columns][-3:-1]\n",
    "        return self.predict(data_for_predict)\n",
    "\n",
    "    def predict(self,data_for_predit:pd.DataFrame) -> tuple:\n",
    "        if not self.model:\n",
    "            raise Exception(\"Must be train first.\")\n",
    "        current_predict_class = self.model.predict(data_for_predit)\n",
    "        current_predict_probability = self.model.predict_proba(data_for_predit)\n",
    "        current_predict_probability = np.amax(\n",
    "        current_predict_probability, axis=1, keepdims=True)\n",
    "        return current_predict_class\n",
    "    \n",
    "CoreML().train(df,config['training_params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
